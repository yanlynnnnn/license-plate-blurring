{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from Stats import Splitter\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AvgFramesLeftTurn</th>\n",
       "      <th>AvgFramesRightTurn</th>\n",
       "      <th>AvgFramesMerge</th>\n",
       "      <th>AvgFramesUTurn</th>\n",
       "      <th>IntersectionMaxAcc</th>\n",
       "      <th>IntersectionAvgAcc</th>\n",
       "      <th>IntersectionVarAcc</th>\n",
       "      <th>IntersectionMaxYaw</th>\n",
       "      <th>IntersectionAvgYaw</th>\n",
       "      <th>IntersectionVarYaw</th>\n",
       "      <th>...</th>\n",
       "      <th>MergeMaxYaw</th>\n",
       "      <th>MergeAvgYaw</th>\n",
       "      <th>MergeVarYaw</th>\n",
       "      <th>UTurnMaxAcc</th>\n",
       "      <th>UTurnAvgAcc</th>\n",
       "      <th>UTurnVarAcc</th>\n",
       "      <th>UTurnMaxYaw</th>\n",
       "      <th>UTurnAvgYaw</th>\n",
       "      <th>UTurnVarYaw</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.022657</td>\n",
       "      <td>-0.841095</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.034730</td>\n",
       "      <td>0.569793</td>\n",
       "      <td>-0.107249</td>\n",
       "      <td>-0.677880</td>\n",
       "      <td>-0.170996</td>\n",
       "      <td>-0.322533</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.303128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.814371</td>\n",
       "      <td>-1.018391</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.062706</td>\n",
       "      <td>0.447115</td>\n",
       "      <td>-0.703907</td>\n",
       "      <td>1.006835</td>\n",
       "      <td>-1.213577</td>\n",
       "      <td>1.010875</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.303128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.256352</td>\n",
       "      <td>-0.663798</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.342463</td>\n",
       "      <td>-0.680043</td>\n",
       "      <td>-0.061242</td>\n",
       "      <td>-0.607683</td>\n",
       "      <td>0.184810</td>\n",
       "      <td>-0.363580</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.303128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.018391</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.105148</td>\n",
       "      <td>-0.174470</td>\n",
       "      <td>-0.081112</td>\n",
       "      <td>-0.046111</td>\n",
       "      <td>-0.134974</td>\n",
       "      <td>-0.278161</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.303128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.814371</td>\n",
       "      <td>-0.841095</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.370438</td>\n",
       "      <td>-0.420949</td>\n",
       "      <td>-0.385951</td>\n",
       "      <td>1.989586</td>\n",
       "      <td>-0.899950</td>\n",
       "      <td>3.905272</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.303128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1365</th>\n",
       "      <td>0.022657</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.776564</td>\n",
       "      <td>1.722847</td>\n",
       "      <td>0.350910</td>\n",
       "      <td>0.024085</td>\n",
       "      <td>-0.397178</td>\n",
       "      <td>-0.253835</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.806791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1366</th>\n",
       "      <td>0.208663</td>\n",
       "      <td>-0.309205</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.276598</td>\n",
       "      <td>0.412880</td>\n",
       "      <td>-0.561455</td>\n",
       "      <td>0.233737</td>\n",
       "      <td>1.428014</td>\n",
       "      <td>0.891668</td>\n",
       "      <td>-0.072600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.862328</td>\n",
       "      <td>0.486498</td>\n",
       "      <td>1.014324</td>\n",
       "      <td>-0.270132</td>\n",
       "      <td>-0.263974</td>\n",
       "      <td>0.501930</td>\n",
       "      <td>1.806791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1367</th>\n",
       "      <td>0.301666</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.330281</td>\n",
       "      <td>0.245026</td>\n",
       "      <td>1.014603</td>\n",
       "      <td>0.014600</td>\n",
       "      <td>-0.467290</td>\n",
       "      <td>-0.127200</td>\n",
       "      <td>-0.230330</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.337165</td>\n",
       "      <td>0.174637</td>\n",
       "      <td>0.217262</td>\n",
       "      <td>0.473558</td>\n",
       "      <td>0.797583</td>\n",
       "      <td>-0.646166</td>\n",
       "      <td>1.806791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1368</th>\n",
       "      <td>-0.256352</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.046796</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.398414</td>\n",
       "      <td>-1.162508</td>\n",
       "      <td>0.152984</td>\n",
       "      <td>-0.537487</td>\n",
       "      <td>0.358867</td>\n",
       "      <td>-0.362286</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.210055</td>\n",
       "      <td>-0.126709</td>\n",
       "      <td>-0.321549</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.806791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369</th>\n",
       "      <td>-0.070346</td>\n",
       "      <td>-0.604699</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.496807</td>\n",
       "      <td>0.733689</td>\n",
       "      <td>1.279645</td>\n",
       "      <td>-0.607683</td>\n",
       "      <td>-0.284337</td>\n",
       "      <td>-0.313472</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.806791</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1370 rows Ã— 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      AvgFramesLeftTurn  AvgFramesRightTurn  AvgFramesMerge  AvgFramesUTurn  \\\n",
       "0              0.022657           -0.841095        0.000000        0.000000   \n",
       "1             -0.814371           -1.018391        0.000000        0.000000   \n",
       "2             -0.256352           -0.663798        0.000000        0.000000   \n",
       "3              0.000000           -1.018391        0.000000        0.000000   \n",
       "4             -0.814371           -0.841095        0.000000        0.000000   \n",
       "...                 ...                 ...             ...             ...   \n",
       "1365           0.022657            0.000000        0.000000        0.000000   \n",
       "1366           0.208663           -0.309205        0.000000       -0.276598   \n",
       "1367           0.301666            0.000000        0.000000        2.330281   \n",
       "1368          -0.256352            0.000000       -0.046796        0.000000   \n",
       "1369          -0.070346           -0.604699        0.000000        0.000000   \n",
       "\n",
       "      IntersectionMaxAcc  IntersectionAvgAcc  IntersectionVarAcc  \\\n",
       "0              -0.034730            0.569793           -0.107249   \n",
       "1              -0.062706            0.447115           -0.703907   \n",
       "2              -0.342463           -0.680043           -0.061242   \n",
       "3               0.105148           -0.174470           -0.081112   \n",
       "4              -0.370438           -0.420949           -0.385951   \n",
       "...                  ...                 ...                 ...   \n",
       "1365            0.776564            1.722847            0.350910   \n",
       "1366            0.412880           -0.561455            0.233737   \n",
       "1367            0.245026            1.014603            0.014600   \n",
       "1368           -0.398414           -1.162508            0.152984   \n",
       "1369            0.496807            0.733689            1.279645   \n",
       "\n",
       "      IntersectionMaxYaw  IntersectionAvgYaw  IntersectionVarYaw  ...  \\\n",
       "0              -0.677880           -0.170996           -0.322533  ...   \n",
       "1               1.006835           -1.213577            1.010875  ...   \n",
       "2              -0.607683            0.184810           -0.363580  ...   \n",
       "3              -0.046111           -0.134974           -0.278161  ...   \n",
       "4               1.989586           -0.899950            3.905272  ...   \n",
       "...                  ...                 ...                 ...  ...   \n",
       "1365            0.024085           -0.397178           -0.253835  ...   \n",
       "1366            1.428014            0.891668           -0.072600  ...   \n",
       "1367           -0.467290           -0.127200           -0.230330  ...   \n",
       "1368           -0.537487            0.358867           -0.362286  ...   \n",
       "1369           -0.607683           -0.284337           -0.313472  ...   \n",
       "\n",
       "      MergeMaxYaw  MergeAvgYaw  MergeVarYaw  UTurnMaxAcc  UTurnAvgAcc  \\\n",
       "0        0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "1        0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "2        0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "3        0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "4        0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "1365     0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "1366     0.000000     0.000000     0.000000     0.862328     0.486498   \n",
       "1367     0.000000     0.000000     0.000000     0.337165     0.174637   \n",
       "1368    -0.210055    -0.126709    -0.321549     0.000000     0.000000   \n",
       "1369     0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "\n",
       "      UTurnVarAcc  UTurnMaxYaw  UTurnAvgYaw  UTurnVarYaw      Date  \n",
       "0        0.000000     0.000000     0.000000     0.000000 -1.303128  \n",
       "1        0.000000     0.000000     0.000000     0.000000 -1.303128  \n",
       "2        0.000000     0.000000     0.000000     0.000000 -1.303128  \n",
       "3        0.000000     0.000000     0.000000     0.000000 -1.303128  \n",
       "4        0.000000     0.000000     0.000000     0.000000 -1.303128  \n",
       "...           ...          ...          ...          ...       ...  \n",
       "1365     0.000000     0.000000     0.000000     0.000000  1.806791  \n",
       "1366     1.014324    -0.270132    -0.263974     0.501930  1.806791  \n",
       "1367     0.217262     0.473558     0.797583    -0.646166  1.806791  \n",
       "1368     0.000000     0.000000     0.000000     0.000000  1.806791  \n",
       "1369     0.000000     0.000000     0.000000     0.000000  1.806791  \n",
       "\n",
       "[1370 rows x 65 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pickle.load(open('scaled_df.pkl', 'rb'))\n",
    "df = df.fillna(0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[:1000]\n",
    "val_df = df[1000:]\n",
    "enrollment_df = val_df[(val_df.index % 10 < 5)]\n",
    "verification_df = val_df[(val_df.index % 10 >= 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = train_df.to_numpy()\n",
    "train_X = train_data[:, :-1]\n",
    "train_Y = train_data[:, -1]\n",
    "label_encoder = LabelEncoder()\n",
    "train_integer_encoded = label_encoder.fit_transform(train_Y)\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "train_integer_encoded = train_integer_encoded.reshape(len(train_integer_encoded), 1)\n",
    "train_Y_encoded = onehot_encoder.fit_transform(train_integer_encoded)\n",
    "train_Y_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 512)               33280     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               25700     \n",
      "=================================================================\n",
      "Total params: 190,308\n",
      "Trainable params: 190,308\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512, input_dim=64, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(100, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "50/50 [==============================] - 1s 2ms/step - loss: 4.5811 - accuracy: 0.0120\n",
      "Epoch 2/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 4.1329 - accuracy: 0.1100\n",
      "Epoch 3/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 3.6892 - accuracy: 0.1810\n",
      "Epoch 4/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 3.2560 - accuracy: 0.2480\n",
      "Epoch 5/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 2.8810 - accuracy: 0.3310\n",
      "Epoch 6/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 2.5529 - accuracy: 0.3970\n",
      "Epoch 7/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 2.2681 - accuracy: 0.4450\n",
      "Epoch 8/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 2.0343 - accuracy: 0.5130\n",
      "Epoch 9/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 1.8269 - accuracy: 0.5650\n",
      "Epoch 10/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 1.6567 - accuracy: 0.6070\n",
      "Epoch 11/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 1.5092 - accuracy: 0.6340\n",
      "Epoch 12/200\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 1.3788 - accuracy: 0.6780\n",
      "Epoch 13/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 1.2676 - accuracy: 0.7080\n",
      "Epoch 14/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 1.2011 - accuracy: 0.7180\n",
      "Epoch 15/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 1.1161 - accuracy: 0.7360\n",
      "Epoch 16/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 1.0503 - accuracy: 0.7590\n",
      "Epoch 17/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.9958 - accuracy: 0.7690\n",
      "Epoch 18/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.9523 - accuracy: 0.7780\n",
      "Epoch 19/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.9222 - accuracy: 0.7870\n",
      "Epoch 20/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.8742 - accuracy: 0.7910\n",
      "Epoch 21/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.8423 - accuracy: 0.7990\n",
      "Epoch 22/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.8110 - accuracy: 0.8000\n",
      "Epoch 23/200\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.8076 - accuracy: 0.8070\n",
      "Epoch 24/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.7777 - accuracy: 0.8120\n",
      "Epoch 25/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.7624 - accuracy: 0.8030\n",
      "Epoch 26/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.7619 - accuracy: 0.8060\n",
      "Epoch 27/200\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.7824 - accuracy: 0.7950\n",
      "Epoch 28/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.7451 - accuracy: 0.8150\n",
      "Epoch 29/200\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.7238 - accuracy: 0.8190\n",
      "Epoch 30/200\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.7135 - accuracy: 0.8170\n",
      "Epoch 31/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.8200\n",
      "Epoch 32/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.7008 - accuracy: 0.8200\n",
      "Epoch 33/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6877 - accuracy: 0.8220\n",
      "Epoch 34/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6753 - accuracy: 0.8250\n",
      "Epoch 35/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6673 - accuracy: 0.8250\n",
      "Epoch 36/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6635 - accuracy: 0.8270\n",
      "Epoch 37/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6762 - accuracy: 0.8230\n",
      "Epoch 38/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6604 - accuracy: 0.8290\n",
      "Epoch 39/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6572 - accuracy: 0.8270\n",
      "Epoch 40/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6481 - accuracy: 0.8280\n",
      "Epoch 41/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6372 - accuracy: 0.8300\n",
      "Epoch 42/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6382 - accuracy: 0.8270\n",
      "Epoch 43/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6278 - accuracy: 0.8310\n",
      "Epoch 44/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6309 - accuracy: 0.8320\n",
      "Epoch 45/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6228 - accuracy: 0.8360\n",
      "Epoch 46/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6159 - accuracy: 0.8320\n",
      "Epoch 47/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6179 - accuracy: 0.8360\n",
      "Epoch 48/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6140 - accuracy: 0.8370\n",
      "Epoch 49/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6158 - accuracy: 0.8350\n",
      "Epoch 50/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6091 - accuracy: 0.8370\n",
      "Epoch 51/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6110 - accuracy: 0.8380\n",
      "Epoch 52/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6108 - accuracy: 0.8380\n",
      "Epoch 53/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6053 - accuracy: 0.8410\n",
      "Epoch 54/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6052 - accuracy: 0.8350\n",
      "Epoch 55/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5968 - accuracy: 0.8410\n",
      "Epoch 56/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5921 - accuracy: 0.8410\n",
      "Epoch 57/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5918 - accuracy: 0.8430\n",
      "Epoch 58/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5968 - accuracy: 0.8410\n",
      "Epoch 59/200\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.5913 - accuracy: 0.8450\n",
      "Epoch 60/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5988 - accuracy: 0.8370\n",
      "Epoch 61/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6419 - accuracy: 0.8290\n",
      "Epoch 62/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.8395 - accuracy: 0.7830\n",
      "Epoch 63/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 1.0325 - accuracy: 0.7490\n",
      "Epoch 64/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.8724 - accuracy: 0.7810\n",
      "Epoch 65/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.7749 - accuracy: 0.8110\n",
      "Epoch 66/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6836 - accuracy: 0.8310\n",
      "Epoch 67/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6058 - accuracy: 0.8440\n",
      "Epoch 68/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5882 - accuracy: 0.8450\n",
      "Epoch 69/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5865 - accuracy: 0.8530\n",
      "Epoch 70/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5944 - accuracy: 0.8420\n",
      "Epoch 71/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5806 - accuracy: 0.8470\n",
      "Epoch 72/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5707 - accuracy: 0.8520\n",
      "Epoch 73/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5690 - accuracy: 0.8510\n",
      "Epoch 74/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5664 - accuracy: 0.8540\n",
      "Epoch 75/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5621 - accuracy: 0.8530\n",
      "Epoch 76/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5625 - accuracy: 0.8510\n",
      "Epoch 77/200\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.5644 - accuracy: 0.8500\n",
      "Epoch 78/200\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.5613 - accuracy: 0.8490\n",
      "Epoch 79/200\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.5648 - accuracy: 0.8520\n",
      "Epoch 80/200\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.5634 - accuracy: 0.8520\n",
      "Epoch 81/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5579 - accuracy: 0.8490\n",
      "Epoch 82/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5598 - accuracy: 0.8500\n",
      "Epoch 83/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5576 - accuracy: 0.8540\n",
      "Epoch 84/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5606 - accuracy: 0.8500\n",
      "Epoch 85/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5606 - accuracy: 0.8520\n",
      "Epoch 86/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5638 - accuracy: 0.8500\n",
      "Epoch 87/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5573 - accuracy: 0.8530\n",
      "Epoch 88/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5591 - accuracy: 0.8500\n",
      "Epoch 89/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.5571 - accuracy: 0.8540\n",
      "Epoch 90/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5546 - accuracy: 0.8480\n",
      "Epoch 91/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5616 - accuracy: 0.8500\n",
      "Epoch 92/200\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.5521 - accuracy: 0.8570\n",
      "Epoch 93/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5486 - accuracy: 0.8520\n",
      "Epoch 94/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5516 - accuracy: 0.8510\n",
      "Epoch 95/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5529 - accuracy: 0.8510\n",
      "Epoch 96/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5501 - accuracy: 0.8530\n",
      "Epoch 97/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5485 - accuracy: 0.8560\n",
      "Epoch 98/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5509 - accuracy: 0.8500\n",
      "Epoch 99/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5511 - accuracy: 0.8570\n",
      "Epoch 100/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5507 - accuracy: 0.8470\n",
      "Epoch 101/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5484 - accuracy: 0.8570\n",
      "Epoch 102/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5527 - accuracy: 0.8530\n",
      "Epoch 103/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5492 - accuracy: 0.8540\n",
      "Epoch 104/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5533 - accuracy: 0.8480\n",
      "Epoch 105/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5525 - accuracy: 0.8530\n",
      "Epoch 106/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5486 - accuracy: 0.8500\n",
      "Epoch 107/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5471 - accuracy: 0.8520\n",
      "Epoch 108/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5498 - accuracy: 0.8520\n",
      "Epoch 109/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5474 - accuracy: 0.8540\n",
      "Epoch 110/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5449 - accuracy: 0.8500\n",
      "Epoch 111/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5425 - accuracy: 0.8580\n",
      "Epoch 112/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5425 - accuracy: 0.8580\n",
      "Epoch 113/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5431 - accuracy: 0.8530\n",
      "Epoch 114/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5467 - accuracy: 0.8520\n",
      "Epoch 115/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5452 - accuracy: 0.8520\n",
      "Epoch 116/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5473 - accuracy: 0.8570\n",
      "Epoch 117/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5446 - accuracy: 0.8570\n",
      "Epoch 118/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5506 - accuracy: 0.8510\n",
      "Epoch 119/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5445 - accuracy: 0.8520\n",
      "Epoch 120/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5559 - accuracy: 0.8530\n",
      "Epoch 121/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5505 - accuracy: 0.8530\n",
      "Epoch 122/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5564 - accuracy: 0.8510\n",
      "Epoch 123/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5490 - accuracy: 0.8570\n",
      "Epoch 124/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6363 - accuracy: 0.8350\n",
      "Epoch 125/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.9931 - accuracy: 0.7610\n",
      "Epoch 126/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 1.0338 - accuracy: 0.7270\n",
      "Epoch 127/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.7218 - accuracy: 0.8060\n",
      "Epoch 128/200\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.6534 - accuracy: 0.8290\n",
      "Epoch 129/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6018 - accuracy: 0.8530\n",
      "Epoch 130/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5649 - accuracy: 0.8520\n",
      "Epoch 131/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5439 - accuracy: 0.8570\n",
      "Epoch 132/200\n",
      "50/50 [==============================] - 0s 3ms/step - loss: 0.5412 - accuracy: 0.8540\n",
      "Epoch 133/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5392 - accuracy: 0.8610\n",
      "Epoch 134/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5379 - accuracy: 0.8560\n",
      "Epoch 135/200\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.5375 - accuracy: 0.8610\n",
      "Epoch 136/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5369 - accuracy: 0.8580\n",
      "Epoch 137/200\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.5387 - accuracy: 0.8590\n",
      "Epoch 138/200\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.5365 - accuracy: 0.8600\n",
      "Epoch 139/200\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.5353 - accuracy: 0.8560\n",
      "Epoch 140/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5371 - accuracy: 0.8590\n",
      "Epoch 141/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5336 - accuracy: 0.8600\n",
      "Epoch 142/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5348 - accuracy: 0.8530\n",
      "Epoch 143/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5346 - accuracy: 0.8600\n",
      "Epoch 144/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5354 - accuracy: 0.8580\n",
      "Epoch 145/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5337 - accuracy: 0.8600\n",
      "Epoch 146/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5339 - accuracy: 0.8580\n",
      "Epoch 147/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5346 - accuracy: 0.8590\n",
      "Epoch 148/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5344 - accuracy: 0.8600\n",
      "Epoch 149/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5323 - accuracy: 0.8580\n",
      "Epoch 150/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5340 - accuracy: 0.8600\n",
      "Epoch 151/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5339 - accuracy: 0.8610\n",
      "Epoch 152/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5331 - accuracy: 0.8570\n",
      "Epoch 153/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5339 - accuracy: 0.8530\n",
      "Epoch 154/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5358 - accuracy: 0.8540\n",
      "Epoch 155/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5360 - accuracy: 0.8590\n",
      "Epoch 156/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5355 - accuracy: 0.8530\n",
      "Epoch 157/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5336 - accuracy: 0.8580\n",
      "Epoch 158/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5311 - accuracy: 0.8570\n",
      "Epoch 159/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5339 - accuracy: 0.8600\n",
      "Epoch 160/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5360 - accuracy: 0.8540\n",
      "Epoch 161/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5371 - accuracy: 0.8580\n",
      "Epoch 162/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5384 - accuracy: 0.8560\n",
      "Epoch 163/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5343 - accuracy: 0.8550\n",
      "Epoch 164/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5351 - accuracy: 0.8590\n",
      "Epoch 165/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5359 - accuracy: 0.8520\n",
      "Epoch 166/200\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.5332 - accuracy: 0.8590\n",
      "Epoch 167/200\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.5350 - accuracy: 0.8550\n",
      "Epoch 168/200\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.5310 - accuracy: 0.8610\n",
      "Epoch 169/200\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.5303 - accuracy: 0.8610\n",
      "Epoch 170/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5305 - accuracy: 0.8620\n",
      "Epoch 171/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5290 - accuracy: 0.8590\n",
      "Epoch 172/200\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.5326 - accuracy: 0.8560\n",
      "Epoch 173/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5344 - accuracy: 0.8580\n",
      "Epoch 174/200\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.5335 - accuracy: 0.8570\n",
      "Epoch 175/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5331 - accuracy: 0.8600\n",
      "Epoch 176/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5360 - accuracy: 0.8600\n",
      "Epoch 177/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5411 - accuracy: 0.8570\n",
      "Epoch 178/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5383 - accuracy: 0.8580\n",
      "Epoch 179/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5375 - accuracy: 0.8570\n",
      "Epoch 180/200\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.5325 - accuracy: 0.8590\n",
      "Epoch 181/200\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.5311 - accuracy: 0.8580\n",
      "Epoch 182/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5290 - accuracy: 0.8600\n",
      "Epoch 183/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5308 - accuracy: 0.8560\n",
      "Epoch 184/200\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.5300 - accuracy: 0.8570\n",
      "Epoch 185/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5338 - accuracy: 0.8590\n",
      "Epoch 186/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.7458 - accuracy: 0.8300\n",
      "Epoch 187/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.8260 - accuracy: 0.7890\n",
      "Epoch 188/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.8788 - accuracy: 0.7800\n",
      "Epoch 189/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.7113 - accuracy: 0.8270\n",
      "Epoch 190/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.6390 - accuracy: 0.8380\n",
      "Epoch 191/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5989 - accuracy: 0.8570\n",
      "Epoch 192/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5620 - accuracy: 0.8550\n",
      "Epoch 193/200\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.5357 - accuracy: 0.8560\n",
      "Epoch 194/200\n",
      "50/50 [==============================] - 0s 1ms/step - loss: 0.5319 - accuracy: 0.8610\n",
      "Epoch 195/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5310 - accuracy: 0.8600\n",
      "Epoch 196/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5296 - accuracy: 0.8620\n",
      "Epoch 197/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5282 - accuracy: 0.8610\n",
      "Epoch 198/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5285 - accuracy: 0.8600\n",
      "Epoch 199/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5277 - accuracy: 0.8620\n",
      "Epoch 200/200\n",
      "50/50 [==============================] - 0s 2ms/step - loss: 0.5285 - accuracy: 0.8570\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1493e1ee0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_X, train_Y_encoded, epochs=200, batch_size=20, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "enrollment_data = enrollment_df.to_numpy()\n",
    "verification_data = verification_df.to_numpy()\n",
    "enrollment_data = enrollment_data[:, :-1]\n",
    "verification_data = verification_data[:, :-1]\n",
    "enrollment_pred = model.predict(enrollment_data)\n",
    "verification_pred = model.predict(verification_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37, 100)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_enrollment_pred = np.mean(enrollment_pred.reshape(-1, 5, 100), axis=1)\n",
    "agg_verification_pred = np.mean(verification_pred.reshape(-1, 5, 100), axis=1)\n",
    "agg_verification_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate (s, s) pairs\n",
    "authorized_pairs = []\n",
    "for i in range(len(agg_verification_pred)):\n",
    "    pair = (agg_enrollment_pred[i], agg_verification_pred[i])\n",
    "    authorized_pairs.append(pair)\n",
    "imposter_pairs = []\n",
    "# Generate (s, i) pairs\n",
    "for i in range(len(agg_verification_pred)):\n",
    "    random_i = i\n",
    "    while random_i == i:\n",
    "        random_i = np.random.randint(36)\n",
    "    pair = (agg_enrollment_pred[i], agg_verification_pred[random_i])\n",
    "    imposter_pairs.append(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_false_rejection(threshold: float):\n",
    "    count = 0\n",
    "    for i in range(len(authorized_pairs)):\n",
    "        dist = np.linalg.norm(authorized_pairs[i][0] - authorized_pairs[i][1])\n",
    "        if dist > threshold:\n",
    "            # Authorized user is rejected\n",
    "            count += 1\n",
    "    return count/len(authorized_pairs)\n",
    "\n",
    "def calc_false_acceptance(threshold: float):\n",
    "    count = 0\n",
    "    for i in range(len(imposter_pairs)):\n",
    "        dist = np.linalg.norm(authorized_pairs[i][0] - authorized_pairs[i][1])\n",
    "        if dist <= threshold:\n",
    "            count += 1\n",
    "    return count/len(imposter_pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_rejection_scores = []\n",
    "false_acceptance_scores = []\n",
    "thresholds = [x * 0.05 for x in range(0, 20)]\n",
    "for threshold in thresholds:\n",
    "    false_rejection = calc_false_rejection(threshold)\n",
    "    false_accpetance = calc_false_acceptance(threshold)\n",
    "    false_rejection_scores.append(false_rejection)\n",
    "    false_acceptance_scores.append(false_accpetance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(thresholds, false_rejection_scores, label='False Rejection')\n",
    "plt.plot(thresholds, false_acceptance_scores, label='False Acceptance')\n",
    "plt.title('FRR/FAR Curve')\n",
    "plt.legend(loc='center left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.14 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "397704579725e15f5c7cb49fe5f0341eb7531c82d19f2c29d197e8b64ab5776b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
